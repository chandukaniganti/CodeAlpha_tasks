TASK 1 : WEB SCRAPING 
In this task, I collected data from a public website using Python web scraping techniques. 
I used Requests to access the web page and BeautifulSoup to understand and extract data from the HTML structure. 
Relevant information such as titles, prices, and ratings was gathered and organized into a structured format using Pandas. 
Finally, I created a custom dataset and saved it as a CSV file for further analysis. 
This task helped me understand web navigation, HTML elements, and automated data collection for data analysis purposes.


TASK 2 : EXPLORATORY DATA ANALYSIS (EDA)
Exploratory Data Analysis (EDA) was performed to understand the dataset and uncover insights before modeling.
The data structure, variables, and data types were examined using summary statistics.
Visualizations were used to identify trends, patterns, and anomalies.
Simple statistical comparisons helped validate assumptions and test hypotheses.
Potential data quality issues such as missing values and outliers were also detected for further analysis.


TASK 3 : DATA VISUALIZATION
In this task, raw data was transformed into meaningful visualizations using Python libraries such as Matplotlib and Seaborn.
Various charts including bar charts, line graphs, scatter plots, and box plots were created to identify trends, patterns, and anomalies.
These visualizations helped in understanding relationships between variables and supported data-driven decision-making.
The task strengthened my ability to communicate insights effectively through visual storytelling.
